{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5ce5ec-ce2e-4cfe-b400-6856075c582e",
   "metadata": {},
   "source": [
    "# <center>  $\\color{indigo}{\\text{Data preparation }}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60016b25-4764-48e2-8de7-a424a29768b2",
   "metadata": {},
   "source": [
    "## <center>  $\\color{indigo}{\\text{Bellevue University. }}$ </center>\n",
    "## <center>  $\\color{indigo}{\\text{DSC 540 }}$ </center>\n",
    "#### <center>  $\\color{indigo}{\\text{Movie Data Analysis}}$ </center>\n",
    "### <center>  $\\color{indigo}{\\text{ Project Milestone - 2. }}$ </center>\n",
    "### <center>  $\\color{indigo}{\\text{ SAMUEL ABOYE. }}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc9551-3261-4026-968e-59af15fa047c",
   "metadata": {},
   "source": [
    "### **Data Cleaning and Preparation Process**\n",
    "#### **Cleaning/Formatting Flat File Source**\n",
    "\n",
    "- This Jupyter Notebook outlines the steps taken to clean and prepare a dataset of movie details for further analysis. The process includes formatting dates, standardizing textual data, parsing JSON formatted columns, and removing duplicates. The dataset includes various attributes such as budget, genres, and viewer ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82087416-396b-4ece-b5bf-5433a852780d",
   "metadata": {},
   "source": [
    "##### **Import Necessary Libraries**\n",
    "\n",
    "Before we start, we need to import the necessary libraries. This script uses `pandas` for data manipulation and `json` for parsing JSON data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b78b2-6872-4a7d-8a1e-31ee26fb3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d7f67-da66-4393-945b-c4e2decf3ac2",
   "metadata": {},
   "source": [
    "#### **Replace Headers**\n",
    "\n",
    "This function replaces existing DataFrame headers with new, more descriptive headers, improving readability and making the data easier to work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d5640-35ee-4c05-96c3-1e1767d30847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1: Replace Headers\n",
    "# Description: Replace existing headers with more descriptive ones for clarity.\n",
    "def replace_headers(df, new_headers):\n",
    "    \"\"\"\n",
    "    Replace existing DataFrame headers with new, descriptive headers.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame whose headers are to be replaced.\n",
    "        new_headers (list of str): A list of new header strings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with updated headers.\n",
    "    \"\"\"\n",
    "    df.columns = new_headers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca461f-4925-4274-8bd8-2ac3169f8507",
   "metadata": {},
   "source": [
    "##### **Format Dates**\n",
    "\n",
    "Converts the 'release_date' column from string format to datetime format, which facilitates date-related operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605a8f5-b3ad-4311-b90f-7753f0093226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #2: Format Date Data\n",
    "# Description: Convert 'release_date' from string format to datetime format for easier manipulation.\n",
    "def format_dates(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a column in DataFrame from string format to datetime format.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to modify.\n",
    "        column_name (str): The name of the column to format.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with formatted date column.\n",
    "    \"\"\"\n",
    "    df[column_name] = pd.to_datetime(df[column_name], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113826c-b079-430e-b0cc-5abfd945b1bd",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "\n",
    "Removes duplicate rows based on the 'ID' column to ensure data uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fb3bc-a1a2-42f3-aea6-ca7673fdd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #3: Remove Duplicates\n",
    "# Description: Remove duplicate rows based on the 'id' column to ensure data uniqueness.\n",
    "def remove_duplicates(df, column_name):\n",
    "    \"\"\"\n",
    "    Remove duplicate rows in the DataFrame based on a specific column.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame from which to remove duplicates.\n",
    "        column_name (str): The column to use for determining duplicates.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(subset=column_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458b2d8-879a-4799-9411-832f58a84231",
   "metadata": {},
   "source": [
    "#### **Standardize Text Data**\n",
    "\n",
    "Standardizes all text in the 'original_title' and 'tagline' columns to lowercase to maintain consistency across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76e4b4-216d-40cd-a859-6097a4051d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #4: Standardize Text Data\n",
    "# Description: Convert all text data in 'original_title' and 'tagline' to lowercase to ensure uniformity.\n",
    "def standardize_text(df, columns):\n",
    "    \"\"\"\n",
    "    Convert all text data in specified columns to lowercase for uniformity.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to modify.\n",
    "        columns (list of str): List of column names to be standardized.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with standardized text data.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21481a59-2ade-45b4-9ead-a118aa799b42",
   "metadata": {},
   "source": [
    "#### **Parse JSON Columns**\n",
    "\n",
    "Parses JSON formatted strings in several columns, converting them into a comma-separated string of names. This simplifies the data and makes it more accessible for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17451b5-143b-4e0f-a6f7-5ee8d943989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #5: Parse JSON Columns\n",
    "# Description: Convert JSON formatted strings in specified columns into a comma-separated string of names.\n",
    "def parse_json_column(data, column):\n",
    "    \"\"\"\n",
    "    Convert JSON formatted strings in a DataFrame column into a comma-separated string of names.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the JSON data.\n",
    "        column (str): The column with JSON strings.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of parsed strings or None for each row in the DataFrame column.\n",
    "    \"\"\"\n",
    "    parsed_column = []\n",
    "    for item in data[column]:\n",
    "        try:\n",
    "            result = json.loads(item.replace(\"'\", '\"'))\n",
    "            names = ', '.join([i['name'] for i in result if 'name' in i])\n",
    "            parsed_column.append(names)\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            parsed_column.append(None)\n",
    "    return parsed_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5cfceb-a4b2-48a1-878a-71867e848e26",
   "metadata": {},
   "source": [
    "# Data Source Description\n",
    "\n",
    "## Overview\n",
    "\n",
    "This dataset is sourced from the [TMDB Movie Metadata dataset on Kaggle](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata). It contains metadata on over 5,000 movies from The Movie Database (TMDB). This dataset is popular for data analysis and machine learning projects due to its rich movie attributes and financial and popularity metrics.\n",
    "\n",
    "## Content\n",
    "\n",
    "The dataset comprises two files:\n",
    "\n",
    "- `tmdb_5000_movies.csv`: Contains essential metadata for each movie, including budget, revenue, release dates, languages, production countries, and several metrics reflecting the movieâ€™s popularity.\n",
    "- `tmdb_5000_credits.csv`: Includes cast and crew information for the movies, providing detailed insights into the people involved in film production.\n",
    "\n",
    "## Features\n",
    "\n",
    "Key features of the `tmdb_5000_movies.csv` include:\n",
    "- `budget`: The budget of the movie.\n",
    "- `genres`: The genre of the movie, formatted as a JSON list of dictionaries.\n",
    "- `homepage`: URL of the movie's homepage.\n",
    "- `id`: The identifier for the movie.\n",
    "- `keywords`: Relevant keywords or tags related to the movie, formatted similarly to genres.\n",
    "- `original_language`: The language in which the movie was originally made.\n",
    "- `original_title`: The title of the movie in its original language.\n",
    "- `overview`: A brief description of the movie.\n",
    "- `popularity`: A metric quantifying the popularity of the movie.\n",
    "- `production_companies`: The production companies involved in making the movie, in JSON format.\n",
    "- `production_countries`: The countries where the movie was produced, in JSON format.\n",
    "- `release_date`: The release date of the movie.\n",
    "- `revenue`: The total worldwide box office revenue generated by the movie.\n",
    "- `runtime`: The duration of the movie in minutes.\n",
    "- `spoken_languages`: The languages spoken in the movie, in JSON format.\n",
    "- `status`: The status of the movie (e.g., Released, Rumored).\n",
    "- `tagline`: The movie's tagline.\n",
    "- `title`: The title of the movie.\n",
    "- `vote_average`: Average rating of the movie.\n",
    "- `vote_count`: Number of votes by viewers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b077e-e561-4ca6-8bd3-e0f7049d1d27",
   "metadata": {},
   "source": [
    "#### **Load and Clean Data**\n",
    "\n",
    "Now we load the data from a CSV file, apply all the cleaning transformations defined above, and check the first few rows of the cleaned dataset to ensure the operations were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504c634-1ffa-4e82-b81e-47acdd9193d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57aff0c-6e19-4e50-97d4-cd6a867307af",
   "metadata": {},
   "source": [
    "#### **Apply transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b71d2e-d113-47f1-81d4-cddc823a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations\n",
    "new_headers = ['Budget', 'Genres', 'Homepage', 'ID', 'Keywords', 'Original_Language', 'Original_Title', 'Overview', 'Popularity', 'Production_Companies', 'Production_Countries', 'Release_Date', 'Revenue', 'Runtime', 'Spoken_Languages', 'Status', 'Tagline', 'Title', 'Vote_Average', 'Vote_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e177a-d0e7-43d8-b028-65cba2c2a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_headers(df, new_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7d96e-a11f-4f2f-a4f1-f7a6e4244d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = format_dates(df, 'Release_Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008fb58-e4cb-4cfc-8116-6f554c53f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_duplicates(df, 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b3b94-54e8-42d5-a845-3d83580d3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = standardize_text(df, ['Original_Title', 'Tagline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe57ca-c670-4f21-bfb4-595f488f11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_columns = ['Genres', 'Keywords', 'Production_Companies', 'Production_Countries', 'Spoken_Languages']\n",
    "for column in json_columns:\n",
    "    df[column] = parse_json_column(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7a99d-9cbe-4b74-8f76-3e1d063c77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the cleaned dataset to check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f488a36-17be-43ce-bef4-dfd7fd227019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ac7c2-f992-4aed-9335-8efd10994674",
   "metadata": {},
   "source": [
    "# Ethical Implications of Data Transformation\n",
    "\n",
    "When transforming and cleaning this movie dataset, several steps were taken to enhance data quality and usability. These steps include standardizing headers and text formats, parsing JSON fields into readable formats, removing duplicates, and formatting date fields. Such processes are essential to making data analysis tasks more straightforward and ensuring accuracy.\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "### Data Changes\n",
    "- **Textual Data and Formats**: We standardized textual data and reformatted dates to ensure uniformity and ease of analysis.\n",
    "- **JSON Structures**: Parsing JSON structures makes the data more accessible but may simplify the nuances of data representation.\n",
    "- **Duplicate Removal**: While removing duplicates aids in preventing skewed statistical analyses, it's crucial to ensure that this does not inadvertently remove valid data that appears similar.\n",
    "\n",
    "### Legal and Regulatory Guidelines\n",
    "There are no specific legal restrictions for this publicly available dataset. However, general data handling and privacy principles should always be considered to maintain trust and integrity in data management.\n",
    "\n",
    "### Transformation Risks\n",
    "- **Over-Cleaning**: There's a risk that over-cleaning might lead to the loss of critical data, particularly with automated processes that remove what appears to be duplicates or outliers without manual verification.\n",
    "\n",
    "### Assumptions\n",
    "- **Duplicate Identifiers**: The assumption that duplicate IDs always indicate duplicate entries may not hold if there were errors in data collection or processing.\n",
    "\n",
    "### Data Sourcing\n",
    "- **Source Credibility**: The dataset was sourced from a public movie database, which is presumed to be credible. However, verification against multiple sources is recommended to enhance data reliability.\n",
    "\n",
    "### Ethical Acquisition\n",
    "- **Public Data**: The dataset is assumed to be ethically sourced, containing publicly available information about movies without any personal data.\n",
    "\n",
    "### Mitigation of Ethical Risks\n",
    "- **Transparency and Verification**: Maintain transparency about the data transformations and provide access to the raw data for verification purposes.\n",
    "- **Best Practices**: Regularly update data handling practices to comply with emerging best practices and ethical standards.\n",
    "\n",
    "By addressing these ethical considerations, we aim to ensure that the data cleaning process respects the integrity of the data and provides a solid foundation for any analyses or decisions based on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e23f1-82f3-4833-a97b-28863e7d0a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
